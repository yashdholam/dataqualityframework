{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "973dfe45-4828-4cc2-ab9f-841dc0c1f3a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, ClassVar\n",
    "\n",
    "from great_expectations.compatibility.pyspark import functions as F\n",
    "from great_expectations.core.metric_domain_types import MetricDomainTypes\n",
    "from great_expectations.core.metric_function_types import MetricPartialFunctionTypes\n",
    "from great_expectations.execution_engine import (\n",
    "    ExecutionEngine,\n",
    "    PandasExecutionEngine,\n",
    "    SparkDFExecutionEngine,\n",
    "    SqlAlchemyExecutionEngine,\n",
    ")\n",
    "from great_expectations.expectations.expectation import (\n",
    "    ColumnMapExpectation,\n",
    "    ExpectationValidationResult,\n",
    "    render_evaluation_parameter_string,\n",
    ")\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.expectations.metrics import (\n",
    "    ColumnMapMetricProvider,\n",
    "    column_condition_partial,\n",
    ")\n",
    "from great_expectations.expectations.metrics.metric_provider import metric_partial\n",
    "from great_expectations.render import (\n",
    "    CollapseContent,\n",
    "    RenderedStringTemplateContent,\n",
    "    RenderedTableContent,\n",
    ")\n",
    "from great_expectations.render.renderer.renderer import renderer\n",
    "from great_expectations.render.util import num_to_str\n",
    "from great_expectations.validator.metric_configuration import MetricConfiguration\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "class ColumnValuesEqualThree(ColumnMapMetricProvider):\n",
    "    condition_metric_name = \"column_values.equal_three_dss\"\n",
    "    condition_value_keys = (\"mostly\", \"value\")\n",
    "\n",
    "    @column_condition_partial(engine=PandasExecutionEngine)\n",
    "    def _pandas(cls, column, **kwargs):\n",
    "        value = kwargs.get(\"value\")\n",
    "        return column == value\n",
    "\n",
    "    @metric_partial(\n",
    "        engine=SparkDFExecutionEngine,\n",
    "        partial_fn_type=MetricPartialFunctionTypes.MAP_CONDITION_FN,\n",
    "        domain_type=MetricDomainTypes.COLUMN,\n",
    "    )\n",
    "    def _spark(\n",
    "        cls,\n",
    "        execution_engine: SparkDFExecutionEngine,\n",
    "        metric_domain_kwargs,\n",
    "        metric_value_kwargs,\n",
    "        metrics,\n",
    "        runtime_configuration,\n",
    "        **kwargs,  # Ensure kwargs is included here\n",
    "    ):\n",
    "        (\n",
    "            selectable,\n",
    "            compute_domain_kwargs,\n",
    "            accessor_domain_kwargs,\n",
    "        ) = execution_engine.get_compute_domain(\n",
    "            metric_domain_kwargs, MetricDomainTypes.COLUMN\n",
    "        )\n",
    "\n",
    "        column_name = accessor_domain_kwargs[\"column\"]\n",
    "        column = F.col(column_name)\n",
    "        value = metric_value_kwargs.get(\"value\")\n",
    "\n",
    "        query = F.when(column == value, F.lit(False)).otherwise(F.lit(True))\n",
    "\n",
    "        return (query, compute_domain_kwargs, accessor_domain_kwargs)\n",
    "\n",
    "    @column_condition_partial(engine=SqlAlchemyExecutionEngine)\n",
    "    def _sqlalchemy(cls, column, **kwargs):\n",
    "        value = kwargs.get(\"value\")\n",
    "        return column.in_([value])\n",
    "\n",
    "    @classmethod\n",
    "    def _get_evaluation_dependencies(\n",
    "        cls,\n",
    "        metric: MetricConfiguration,\n",
    "        configuration: Optional[ExpectationConfiguration] = None,\n",
    "        execution_engine: Optional[ExecutionEngine] = None,\n",
    "        runtime_configuration: Optional[Dict] = None,\n",
    "    ):\n",
    "        dependencies: Dict = super()._get_evaluation_dependencies(\n",
    "            metric=metric,\n",
    "            configuration=configuration,\n",
    "            execution_engine=execution_engine,\n",
    "            runtime_configuration=runtime_configuration,\n",
    "        )\n",
    "\n",
    "        table_domain_kwargs: Dict = {\n",
    "            k: v for k, v in metric.metric_domain_kwargs.items() if k != \"column\"\n",
    "        }\n",
    "        dependencies[\"table.column_types\"] = MetricConfiguration(\n",
    "            metric_name=\"table.column_types\",\n",
    "            metric_domain_kwargs=table_domain_kwargs,\n",
    "            metric_value_kwargs={\n",
    "                \"include_nested\": True,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return dependencies\n",
    "\n",
    "class ExpectColumnValuesToEqualToGiven(ColumnMapExpectation):\n",
    "    \"\"\"Expect values in this column to equal a given value.\"\"\"\n",
    "\n",
    "    examples = [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"all_threes\": [3, 3, 3, 3, 3],\n",
    "                \"some_zeroes\": [3, 3, 3, 0, 0],\n",
    "            },\n",
    "            \"tests\": [\n",
    "                {\n",
    "                    \"title\": \"basic_positive_test\",\n",
    "                    \"exact_match_out\": False,\n",
    "                    \"include_in_gallery\": True,\n",
    "                    \"in\": {\"column\": \"all_threes\", \"value\": 3},\n",
    "                    \"out\": {\n",
    "                        \"success\": True,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"basic_negative_test\",\n",
    "                    \"exact_match_out\": False,\n",
    "                    \"include_in_gallery\": True,\n",
    "                    \"in\": {\"column\": \"some_zeroes\", \"value\": 3, \"mostly\": 0.8},\n",
    "                    \"out\": {\n",
    "                        \"success\": False,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    value: int\n",
    "    map_metric = \"column_values.equal_three_dss\"\n",
    "    condition_metric_name = \"column_values.equal_three_dss\"\n",
    "    success_keys = (\"mostly\", \"value\")\n",
    "\n",
    "    @renderer(renderer_type=\"renderer.diagnostic.observed_value\")\n",
    "    @render_evaluation_parameter_string\n",
    "    def _diagnostic_observed_value_renderer(\n",
    "        cls,\n",
    "        configuration: ExpectationConfiguration = None,\n",
    "        result: ExpectationValidationResult = None,\n",
    "        runtime_configuration: Optional[dict] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        assert result, \"Must provide a result object.\"\n",
    "\n",
    "        result_dict = result\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "expect_column_values",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
